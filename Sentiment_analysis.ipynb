{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNavK7l+ah/djX2SKWmXQXY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/digitalempire00/Python/blob/main/Sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kui2jo0NtFp_"
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import json\n",
        "import ast\n",
        "import yaml\n",
        "\n",
        "\n",
        "def create_twitter_url():\n",
        "    handle = \"jessicagarson\"\n",
        "    max_results = 100\n",
        "    mrf = \"max_results={}\".format(max_results)\n",
        "    q = \"query=from:{}\".format(handle)\n",
        "    url = \"https://api.twitter.com/labs/2/tweets/search?{}&{}\".format(mrf, q)\n",
        "    return url\n",
        "\n",
        "\n",
        "def process_yaml():\n",
        "    with open(\"config.yaml\") as file:\n",
        "        return yaml.safe_load(file)\n",
        "\n",
        "\n",
        "def create_bearer_token(data):\n",
        "    return data[\"search_tweets_api\"][\"bearer_token\"]\n",
        "\n",
        "\n",
        "def twitter_auth_and_connect(bearer_token, url):\n",
        "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
        "    response = requests.request(\"GET\", url, headers=headers)\n",
        "    return response.json()\n",
        "\n",
        "\n",
        "def no_tweets(res_json):\n",
        "    if res_json == {\"meta\": {\"result_count\": 0}}:\n",
        "        print(\"The Twitter handle entered hasn't Tweeted in 7 days.\")\n",
        "\n",
        "\n",
        "def lang_data_shape(res_json):\n",
        "    data_only = res_json[\"data\"]\n",
        "    doc_start = '\"documents\": {}'.format(data_only)\n",
        "    str_json = \"{\" + doc_start + \"}\"\n",
        "    dump_doc = json.dumps(str_json)\n",
        "    doc = json.loads(dump_doc)\n",
        "    return ast.literal_eval(doc)\n",
        "\n",
        "\n",
        "def connect_to_azure(data):\n",
        "    azure_url = \"https://week.cognitiveservices.azure.com/\"\n",
        "    language_api_url = \"{}text/analytics/v2.1/languages\".format(azure_url)\n",
        "    sentiment_url = \"{}text/analytics/v2.1/sentiment\".format(azure_url)\n",
        "    subscription_key = data[\"azure\"][\"subscription_key\"]\n",
        "    return language_api_url, sentiment_url, subscription_key\n",
        "\n",
        "\n",
        "def azure_header(subscription_key):\n",
        "    return {\"Ocp-Apim-Subscription-Key\": subscription_key}\n",
        "\n",
        "\n",
        "def generate_languages(headers, language_api_url, documents):\n",
        "    response = requests.post(language_api_url, headers=headers, json=documents)\n",
        "    return response.json()\n",
        "\n",
        "\n",
        "def combine_lang_data(documents, with_languages):\n",
        "    langs = pd.DataFrame(with_languages[\"documents\"])\n",
        "    lang_iso = [x.get(\"iso6391Name\")\n",
        "                for d in langs.detectedLanguages if d for x in d]\n",
        "    data_only = documents[\"documents\"]\n",
        "    tweet_data = pd.DataFrame(data_only)\n",
        "    tweet_data.insert(2, \"language\", lang_iso, True)\n",
        "    json_lines = tweet_data.to_json(orient=\"records\")\n",
        "    return json_lines\n",
        "\n",
        "\n",
        "def add_document_format(json_lines):\n",
        "    docu_format = '\"' + \"documents\" + '\"'\n",
        "    json_docu_format = \"{}:{}\".format(docu_format, json_lines)\n",
        "    docu_align = \"{\" + json_docu_format + \"}\"\n",
        "    jd_align = json.dumps(docu_align)\n",
        "    jl_align = json.loads(jd_align)\n",
        "    return ast.literal_eval(jl_align)\n",
        "\n",
        "\n",
        "def sentiment_scores(headers, sentiment_url, document_format):\n",
        "    response = requests.post(\n",
        "        sentiment_url, headers=headers, json=document_format)\n",
        "    return response.json()\n",
        "\n",
        "\n",
        "def mean_score(sentiments):\n",
        "    sentiment_df = pd.DataFrame(sentiments[\"documents\"])\n",
        "    return sentiment_df[\"score\"].mean()\n",
        "\n",
        "\n",
        "def week_logic(week_score):\n",
        "    if week_score > 0.75 or week_score == 0.75:\n",
        "        print(\"You had a positve week\")\n",
        "    elif week_score > 0.45 or week_score == 0.45:\n",
        "        print(\"You had a neautral week\")\n",
        "    else:\n",
        "        print(\"You had a negative week, I hope it gets better\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    url = create_twitter_url()\n",
        "    data = process_yaml()\n",
        "    bearer_token = create_bearer_token(data)\n",
        "    res_json = twitter_auth_and_connect(bearer_token, url)\n",
        "    no_tweets(res_json)\n",
        "    documents = lang_data_shape(res_json)\n",
        "    language_api_url, sentiment_url, subscription_key = connect_to_azure(data)\n",
        "    headers = azure_header(subscription_key)\n",
        "    with_languages = generate_languages(headers, language_api_url, documents)\n",
        "    json_lines = combine_lang_data(documents, with_languages)\n",
        "    document_format = add_document_format(json_lines)\n",
        "    sentiments = sentiment_scores(headers, sentiment_url, document_format)\n",
        "    week_score = mean_score(sentiments)\n",
        "    print(week_score)\n",
        "    week_logic(week_score)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}